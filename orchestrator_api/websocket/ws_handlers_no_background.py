from flask_socketio import SocketIO, emit
from flask import request
from eventlet import tpool
import requests
import tempfile
import os
import base64
import uuid
from app import socketio
from services.answer_service import (
    stream_text_answer_by_sentence,
    synthesize_wav,
    transcribe_audio
)
import structlog
from dotenv import load_dotenv, find_dotenv
from services.object_extraction_service import extract_scene_objects
from queue import Queue

# Gets the logger instance
logger = structlog.get_logger()

load_dotenv(find_dotenv())
TEXT_TO_IMAGE_URL = os.getenv("ZIMAGE_TURBO_API_URL")
IMAGE_TO_3D_MODEL = os.getenv("IMAGE_TO_3D_MODEL")
if IMAGE_TO_3D_MODEL == "Trellis":
    IMAGE_TO_3D_URL = os.getenv("TRELLIS_API_URL")
else:
    IMAGE_TO_3D_URL = os.getenv("HUNYUAN_API_URL")

@socketio.on('connect')
def on_connect():
    logger.info(f"[WS] CONNECT sid={request.sid}")

@socketio.on('disconnect')
def on_disconnect():
    logger.info(f"[WS] DISCONNECT sid={request.sid}")

@socketio.on("ask")
def handle_ask(data):
    """
    WebSocket event handler.
    Expects:
      - 'audio' (base64), mandatory
      - 'audio_response' (bool), optional
      - 'objects' (int: 0, 1), optional
      - 'max_objects' (int), optional
    """
    # Generate a unique ID for this specific interaction
    rid = str(uuid.uuid4())
    structlog.contextvars.clear_contextvars()
    structlog.contextvars.bind_contextvars(rid=rid, connection="websocket")
    
    logger.info("received_ws_message", payload=data)
    
    try:
        sid = request.sid
        audio_response = data.get("audio_response", True)
        object_gen = int(data.get("objects", 0))
        audio_b64 = data.get("audio_question")
        audio_bytes = base64.b64decode(audio_b64)
        max_objects = data.get("max_objects", 1)
        
        # Save incoming temporary audio
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(audio_bytes)
            tmp_path = tmp.name

        # STT
        transcription, language = transcribe_audio(tmp_path)

        # Buffer to collect the full text answer (optional, depending on if you want summary in logs)
        full_answer = []

        # For each item generated by the LLM:
        # Note: sentence_tuple is now (text_content, message_type)
        for text_content, message_type in stream_text_answer_by_sentence(transcription):

            if message_type == "speech":
                # 1. Handle Speech Text
                # Send text chunk to main chat window
                emit("text_chunk", {"text": text_content})
                full_answer.append(text_content)
                socketio.sleep(0)

                # 2. Generate Audio (Only for speech)
                if audio_response:
                    wav_b64 = synthesize_wav(text_content, language=language)
                    emit("audio_sentence", {"base64": wav_b64})
                    socketio.sleep(0)

            elif message_type == "summary":
                # Handle Summary Text
                emit("summary_chunk", {"text": text_content})
                socketio.sleep(0)

        # Logging
        answer_text = " ".join(full_answer)
        logger.info(f"Tutor response: {answer_text}")

        # Signal end of streams
        emit("text_done", {"status": "completed"})

        if audio_response:
            emit("audio_done", {"status": "completed"})

        # 3D object generation
        if object_gen:
            socketio.start_background_task(
                run_object_generation, sid, transcription, answer_text, object_gen, max_objects
            )

    except Exception as e:
        emit("error", {"message": str(e)})

# Generate 3D models and send their filenames to the client
def run_object_generation(sid, transcription, answer_text, object_gen, max_objects):

    # Retrieve the current rid from the context
    context = structlog.contextvars.get_contextvars()
    rid = context.get("rid")
    # Define common headers to pass the rid to the other microservices
    headers = {"X-Request-ID": rid} if rid else {}
    
    object_descriptions = extract_scene_objects(transcription, answer_text)
    num_generated_obj = 0

    try:
        # Ensure to do not exceed the maximum number of objects requested
        for text_prompt in object_descriptions: 
            #TODO: se vogliamo mantenere questa meccanica, conviene iniettare il numero massimo 
            # direttamente nel prompt quando vengono estratti gli oggetti
            if (num_generated_obj < max_objects):
                num_generated_obj +=1
                socketio.sleep(0)
                
                logger.info("requesting_3d_object", prompt=text_prompt, count=num_generated_obj)

                # --- STEP 1: Text to Image ---
                try:
                    txt2img_response = requests.post(
                        TEXT_TO_IMAGE_URL, 
                        json={"prompt": text_prompt}, 
                        headers=headers,
                        timeout=20
                    )
                except requests.exceptions.RequestException as e:
                    logger.error("txt2img_connection_failed", error=str(e))
                    continue

                if txt2img_response.status_code == 200:
                    img_id = txt2img_response.json().get("image_id")
                    logger.info("image_generated", image_id=img_id)

                    # --- STEP 2: Image to 3D ---
                    try:
                        img2obj_response = requests.post(
                            IMAGE_TO_3D_URL, 
                            json={"img_id": img_id}, 
                            headers=headers,
                            timeout=120
                        )
                    except requests.exceptions.RequestException as e:
                        logger.error("img2obj_connection_failed", error=str(e))
                        continue

                    if img2obj_response.status_code == 200:
                        obj_filename = img2obj_response.json().get("object_id")
                        socketio.emit("object", {"object": obj_filename}, to=sid)
                        logger.info("object_emitted", object_id=obj_filename, sid=sid)
                    else:
                        logger.error("img2obj_error_status", status=img2obj_response.status_code)
                else:
                    logger.error("txt2img_error_status", status=txt2img_response.status_code)

    except Exception as e:
        logger.error("generation_pipeline_crashed", error=str(e))

    socketio.emit("objects_done", {"status": "completed"}, to=sid)
    logger.info("all_objects_processed")